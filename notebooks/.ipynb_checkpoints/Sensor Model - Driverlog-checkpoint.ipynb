{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meta_planning.parsers import parse_trajectory, parse_model\n",
    "from meta_planning import ValidationTask\n",
    "from meta_planning import dataset\n",
    "from meta_planning.pddl import SensorModel\n",
    "from meta_planning.functions import generate_all_literals, get_matching_literals\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = \"blocks\"\n",
    "\n",
    "M = parse_model('benchmarks/%s/trajectories/domain.pddl' % domain)\n",
    "t = parse_trajectory('benchmarks/%s/trajectories/trajectory-01' % domain, M)\n",
    "T = [t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = generate_all_literals(M.predicates, T[0].objects, M.types)\n",
    "\n",
    "mapping = {f:f for f in F}\n",
    "\n",
    "S = SensorModel(mapping,[0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [p for p in M.predicates if p.name in [\"on\", \"ontable\", \"clear\"]]\n",
    "\n",
    "objects = [o for o in T[0].objects if o.type_name == \"nblock\"]\n",
    "\n",
    "subF = get_matching_literals(F, preds, objects)\n",
    "\n",
    "mapping = {f:f for f in subF}\n",
    "\n",
    "S.set_observability(mapping, [0.3,0,0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [p for p in M.predicates if p.name in [\"on\", \"ontable\", \"clear\"]]\n",
    "\n",
    "objects = [o for o in T[0].objects if o.type_name == \"oblock\"]\n",
    "\n",
    "subF = get_matching_literals(F, preds, objects)\n",
    "\n",
    "mapping = {f:f for f in subF}\n",
    "\n",
    "S.set_observability(mapping, [0.7,0,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(on c c) [0.3, 0, 0.7]\n",
      "(on c f) [0.7, 0, 0.3]\n",
      "(on c a) [0.3, 0, 0.7]\n",
      "(on c b) [0.7, 0, 0.3]\n",
      "(on c g) [0.3, 0, 0.7]\n",
      "(on c d) [0.7, 0, 0.3]\n",
      "(on c e) [0.3, 0, 0.7]\n",
      "(on f c) [0.7, 0, 0.3]\n",
      "(on f f) [0.7, 0, 0.3]\n",
      "(on f a) [0.7, 0, 0.3]\n",
      "(on f b) [0.7, 0, 0.3]\n",
      "(on f g) [0.7, 0, 0.3]\n",
      "(on f d) [0.7, 0, 0.3]\n",
      "(on f e) [0.7, 0, 0.3]\n",
      "(on a c) [0.3, 0, 0.7]\n",
      "(on a f) [0.7, 0, 0.3]\n",
      "(on a a) [0.3, 0, 0.7]\n",
      "(on a b) [0.7, 0, 0.3]\n",
      "(on a g) [0.3, 0, 0.7]\n",
      "(on a d) [0.7, 0, 0.3]\n",
      "(on a e) [0.3, 0, 0.7]\n",
      "(on b c) [0.7, 0, 0.3]\n",
      "(on b f) [0.7, 0, 0.3]\n",
      "(on b a) [0.7, 0, 0.3]\n",
      "(on b b) [0.7, 0, 0.3]\n",
      "(on b g) [0.7, 0, 0.3]\n",
      "(on b d) [0.7, 0, 0.3]\n",
      "(on b e) [0.7, 0, 0.3]\n",
      "(on g c) [0.3, 0, 0.7]\n",
      "(on g f) [0.7, 0, 0.3]\n",
      "(on g a) [0.3, 0, 0.7]\n",
      "(on g b) [0.7, 0, 0.3]\n",
      "(on g g) [0.3, 0, 0.7]\n",
      "(on g d) [0.7, 0, 0.3]\n",
      "(on g e) [0.3, 0, 0.7]\n",
      "(on d c) [0.7, 0, 0.3]\n",
      "(on d f) [0.7, 0, 0.3]\n",
      "(on d a) [0.7, 0, 0.3]\n",
      "(on d b) [0.7, 0, 0.3]\n",
      "(on d g) [0.7, 0, 0.3]\n",
      "(on d d) [0.7, 0, 0.3]\n",
      "(on d e) [0.7, 0, 0.3]\n",
      "(on e c) [0.3, 0, 0.7]\n",
      "(on e f) [0.7, 0, 0.3]\n",
      "(on e a) [0.3, 0, 0.7]\n",
      "(on e b) [0.7, 0, 0.3]\n",
      "(on e g) [0.3, 0, 0.7]\n",
      "(on e d) [0.7, 0, 0.3]\n",
      "(on e e) [0.3, 0, 0.7]\n",
      "(ontable c) [0.3, 0, 0.7]\n",
      "(ontable f) [0.7, 0, 0.3]\n",
      "(ontable a) [0.3, 0, 0.7]\n",
      "(ontable b) [0.7, 0, 0.3]\n",
      "(ontable g) [0.3, 0, 0.7]\n",
      "(ontable d) [0.7, 0, 0.3]\n",
      "(ontable e) [0.3, 0, 0.7]\n",
      "(clear c) [0.3, 0, 0.7]\n",
      "(clear f) [0.7, 0, 0.3]\n",
      "(clear a) [0.3, 0, 0.7]\n",
      "(clear b) [0.7, 0, 0.3]\n",
      "(clear g) [0.3, 0, 0.7]\n",
      "(clear d) [0.7, 0, 0.3]\n",
      "(clear e) [0.3, 0, 0.7]\n",
      "(handempty ) [0, 0, 1]\n",
      "(holding c) [0, 0, 1]\n",
      "(holding f) [0, 0, 1]\n",
      "(holding a) [0, 0, 1]\n",
      "(holding b) [0, 0, 1]\n",
      "(holding g) [0, 0, 1]\n",
      "(holding d) [0, 0, 1]\n",
      "(holding e) [0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "for k,v in S.observability_table.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = [t]\n",
    "O = [t.observe_with_sensor_model(S, action_observability=0) for t in T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dieaigar/PhD/meta-planning/src/meta_planning/util/planners/metric-FF/ff -E -O -g 1 -h 0 -o compiled_domain -f compiled_problem -s solution_plan\n"
     ]
    }
   ],
   "source": [
    "valtask = ValidationTask(M,O, sensor_model=S, use_cost=True)\n",
    "sol = valtask.validate(clean=False, planner=\"metric-ff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta-planning",
   "language": "python",
   "name": "meta-planning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
