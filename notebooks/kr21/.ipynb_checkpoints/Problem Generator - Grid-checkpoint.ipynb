{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from planning_inference.parsers import parse_model, parse_problem, parse_plan, parse_trajectory, parse_hypothesis, parse_observation_sequence\n",
    "from planning_inference.generator import generate_trajectory\n",
    "from planning_inference.functions import generate_all_literals, get_matching_literals\n",
    "\n",
    "from planning_inference.pddl import Conjunction, Literal, Type, TypedObject, Effect, Truth, NumericConstant, PrimitiveNumericExpression, Increase\n",
    "from planning_inference.pddl import SensorModel\n",
    "\n",
    "from planning_inference.observations import Trajectory, LTLHypothesis, State\n",
    "\n",
    "from planning_inference import DecodingTask\n",
    "\n",
    "from sensor_models import load_sensor_model\n",
    "\n",
    "import os\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "from itertools import combinations, permutations, product, chain\n",
    "from random import choice, sample, shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordered_occurrence(phis, first_call = False):\n",
    "    if len(phis) == 1:\n",
    "        return \"{}\".format(phis[0])\n",
    "    else:\n",
    "        return \"{} & X(F({}))\".format(phis[0], ordered_occurrence(phis[1:]))\n",
    "#     else:\n",
    "#         return \"X(F({} & {}))\".format(phis[0], ordered_occurrence(phis[1:]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = \"grid\"\n",
    "\n",
    "M = parse_model(\"%s/domain.pddl\" % domain)\n",
    "M.to_file(\"domain.pddl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sensor model\n",
    "Ms = load_sensor_model(domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Planner call\n",
    "optimal = True\n",
    "\n",
    "if optimal:\n",
    "    planner_path = \"/home/dieaigar/PhD/downward/fast-downward.py\"\n",
    "    cmd_args = [planner_path, '--plan-file %s' % \"solution_plan\", \"domain.pddl\", \"problem.pddl\", '--evaluator \"lmc=merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1)\" --search \"astar(lmc,lazy_evaluator=lmc)\"']\n",
    "else:\n",
    "    planner_path = \"/home/dieaigar/PhD/meta-planning/src/meta_planning/util/planners/metric-FF/ff\"\n",
    "    cmd_args = [planner_path, \"-E\", \"-O\", \"-o\", \"domain.pddl\", \"-f\", \"problem.pddl\", \"-s\", \"solution_plan\"]\n",
    "cmd = \" \".join(cmd_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dieaigar/PhD/downward/fast-downward.py --plan-file solution_plan domain.pddl problem.pddl --evaluator \"lmc=merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1)\" --search \"astar(lmc,lazy_evaluator=lmc)\"\n",
      "['node32', 'node33', 'node34', 'node44']\n",
      "[9, 17, 19, 24]\n",
      "17 19 18\n",
      "('node33', 'node44')\n",
      "('node23', 'node33')\n",
      "('node32', 'node33')\n",
      "('node23', 'node43')\n",
      "('node23', 'node34')\n",
      "[18, 10, 5, 13, 1]\n",
      "[18, 10, 5, 13, 1, 8, 9, 12, 3]\n",
      "[18, 10, 5, 13, 1, 8, 9, 12, 3, 4, 0, 7]\n",
      "/home/dieaigar/PhD/downward/fast-downward.py --plan-file solution_plan domain.pddl problem.pddl --evaluator \"lmc=merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1)\" --search \"astar(lmc,lazy_evaluator=lmc)\"\n",
      "['node23', 'node33', 'node34', 'node44']\n",
      "[4, 12, 14, 19]\n",
      "12 14 13\n",
      "('node43', 'node44')\n",
      "('node34', 'node44')\n",
      "('node23', 'node33')\n",
      "('node32', 'node43')\n",
      "('node23', 'node34')\n",
      "[13, 12, 10]\n",
      "[13, 12, 10, 5, 9, 0]\n",
      "[13, 12, 10, 5, 9, 0, 7, 11, 4]\n",
      "/home/dieaigar/PhD/downward/fast-downward.py --plan-file solution_plan domain.pddl problem.pddl --evaluator \"lmc=merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1)\" --search \"astar(lmc,lazy_evaluator=lmc)\"\n",
      "['node23', 'node33', 'node34', 'node44']\n",
      "[6, 14, 16, 21]\n",
      "14 16 14\n",
      "('node23', 'node33')\n",
      "('node32', 'node34')\n",
      "('node32', 'node43')\n",
      "('node23', 'node43')\n",
      "('node33', 'node44')\n",
      "[14, 7, 10, 11]\n",
      "[14, 7, 10, 11, 13, 2, 3]\n",
      "[14, 7, 10, 11, 13, 2, 3, 0, 9]\n",
      "/home/dieaigar/PhD/downward/fast-downward.py --plan-file solution_plan domain.pddl problem.pddl --evaluator \"lmc=merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1)\" --search \"astar(lmc,lazy_evaluator=lmc)\"\n",
      "['node42', 'node43', 'node44']\n",
      "[11, 13, 20]\n",
      "13 20 16\n",
      "('node24', 'node43')\n",
      "('node22', 'node33')\n",
      "('node34', 'node42')\n",
      "('node24', 'node33')\n",
      "('node22', 'node43')\n",
      "('node42', 'node43')\n",
      "[16, 1, 4, 3]\n",
      "[16, 1, 4, 3, 12, 6, 11, 9]\n",
      "[16, 1, 4, 3, 12, 6, 11, 9, 8, 2, 14]\n",
      "/home/dieaigar/PhD/downward/fast-downward.py --plan-file solution_plan domain.pddl problem.pddl --evaluator \"lmc=merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1)\" --search \"astar(lmc,lazy_evaluator=lmc)\"\n",
      "['node23', 'node33', 'node34', 'node44']\n",
      "[8, 11, 13, 20]\n",
      "11 13 11\n",
      "('node33', 'node44')\n",
      "('node23', 'node33')\n",
      "('node23', 'node34')\n",
      "('node32', 'node43')\n",
      "('node32', 'node34')\n",
      "[11, 8, 9]\n",
      "[11, 8, 9, 6, 5]\n",
      "[11, 8, 9, 6, 5, 2, 4]\n",
      "/home/dieaigar/PhD/downward/fast-downward.py --plan-file solution_plan domain.pddl problem.pddl --evaluator \"lmc=merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1)\" --search \"astar(lmc,lazy_evaluator=lmc)\"\n",
      "['node32', 'node33', 'node34', 'node44']\n",
      "[4, 12, 14, 19]\n",
      "12 14 13\n",
      "('node23', 'node34')\n",
      "('node33', 'node44')\n",
      "('node34', 'node44')\n",
      "('node32', 'node43')\n",
      "('node23', 'node33')\n",
      "('node32', 'node33')\n",
      "[13, 4, 12]\n",
      "[13, 4, 12, 2, 5, 3]\n",
      "[13, 4, 12, 2, 5, 3, 6, 11, 10]\n",
      "/home/dieaigar/PhD/downward/fast-downward.py --plan-file solution_plan domain.pddl problem.pddl --evaluator \"lmc=merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1)\" --search \"astar(lmc,lazy_evaluator=lmc)\"\n",
      "['node32', 'node33', 'node34', 'node44']\n",
      "[5, 17, 19, 24]\n",
      "17 19 17\n",
      "('node32', 'node33')\n",
      "('node23', 'node43')\n",
      "('node33', 'node44')\n",
      "('node23', 'node34')\n",
      "('node34', 'node44')\n",
      "[17, 4, 6, 5, 0]\n",
      "[17, 4, 6, 5, 0, 11, 12, 7]\n",
      "[17, 4, 6, 5, 0, 11, 12, 7, 16, 10, 2]\n",
      "/home/dieaigar/PhD/downward/fast-downward.py --plan-file solution_plan domain.pddl problem.pddl --evaluator \"lmc=merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1)\" --search \"astar(lmc,lazy_evaluator=lmc)\"\n",
      "['node23', 'node33', 'node34', 'node44']\n",
      "[8, 16, 18, 23]\n",
      "16 18 16\n",
      "('node34', 'node44')\n",
      "('node23', 'node33')\n",
      "('node32', 'node33')\n",
      "('node33', 'node44')\n",
      "('node23', 'node43')\n",
      "('node43', 'node44')\n",
      "[16, 1, 11, 8]\n",
      "[16, 1, 11, 8, 5, 13, 9, 3]\n",
      "[16, 1, 11, 8, 5, 13, 9, 3, 14, 0, 4]\n",
      "/home/dieaigar/PhD/downward/fast-downward.py --plan-file solution_plan domain.pddl problem.pddl --evaluator \"lmc=merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1)\" --search \"astar(lmc,lazy_evaluator=lmc)\"\n",
      "['node32', 'node33', 'node34', 'node44']\n",
      "[10, 18, 20, 25]\n",
      "18 20 18\n",
      "('node32', 'node43')\n",
      "('node23', 'node34')\n",
      "('node43', 'node44')\n",
      "('node32', 'node33')\n",
      "('node23', 'node43')\n",
      "[18, 8, 14, 15, 5]\n",
      "[18, 8, 14, 15, 5, 17, 0, 3, 9]\n",
      "[18, 8, 14, 15, 5, 17, 0, 3, 9, 1, 11, 6]\n",
      "/home/dieaigar/PhD/downward/fast-downward.py --plan-file solution_plan domain.pddl problem.pddl --evaluator \"lmc=merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1)\" --search \"astar(lmc,lazy_evaluator=lmc)\"\n",
      "['node23', 'node33', 'node34', 'node44']\n",
      "[7, 17, 19, 24]\n",
      "17 19 17\n",
      "('node23', 'node33')\n",
      "('node32', 'node43')\n",
      "('node43', 'node44')\n",
      "('node32', 'node33')\n",
      "('node34', 'node44')\n",
      "[17, 5, 11, 7, 1]\n",
      "[17, 5, 11, 7, 1, 8, 13, 15]\n",
      "[17, 5, 11, 7, 1, 8, 13, 15, 4, 3, 10]\n"
     ]
    }
   ],
   "source": [
    "# Monitoring\n",
    "\n",
    "shapes = {\"triangle\" : [\"node44\",\"node23\",\"node32\"], \"circle\" : [\"node34\",\"node33\",\"node43\"], \"square\" : [\"node24\",\"node22\",\"node42\"]}\n",
    "all_nodes = [node for sublist in shapes.values() for node in sublist]\n",
    "\n",
    "observabilities = [30, 50, 70]\n",
    "cutoff = 2\n",
    "\n",
    "\n",
    "base_path = \"benchmark/%s/monitoring/\" % (domain)\n",
    "\n",
    "if not os.path.exists(base_path):\n",
    "    os.mkdir(base_path)\n",
    "\n",
    "    \n",
    "pcount = 0\n",
    "for pnum in range(10):\n",
    "    \n",
    "    P = parse_problem(\"%s/p%s.pddl\" % (domain, str(pnum+1).zfill(2)), M)\n",
    "    P.to_file(\"problem.pddl\")\n",
    "\n",
    "    print(cmd)\n",
    "    os.system(cmd)\n",
    "\n",
    "    plan = parse_plan(\"solution_plan\")\n",
    "\n",
    "    t = generate_trajectory(M, P, plan)\n",
    "\n",
    "\n",
    "\n",
    "    unlocked_sequence = []\n",
    "    unlocked_states = []\n",
    "\n",
    "    for i in t.states.keys():\n",
    "        open_nodes = [l.args[0]for l in t.states[i].to_close_world().literals if l.predicate == \"open\"]\n",
    "        unlocked_nodes = [node for node in open_nodes if node in all_nodes]\n",
    "\n",
    "        if len(unlocked_nodes) > len(unlocked_sequence):\n",
    "            for node in unlocked_nodes:\n",
    "                if node not in unlocked_sequence:\n",
    "                    unlocked_sequence += [node]\n",
    "\n",
    "            unlocked_states += [i]\n",
    "\n",
    "    min_index = unlocked_states[cutoff-1]\n",
    "    max_index = unlocked_states[cutoff]\n",
    "    selected_index = choice(range(min_index, max_index))\n",
    "\n",
    "\n",
    "    print(unlocked_sequence)\n",
    "    print(unlocked_states)\n",
    "    print(min_index, max_index, selected_index)\n",
    "\n",
    "\n",
    "    # Build hypotheses\n",
    "\n",
    "    H = [] # Hypotheses set\n",
    "    h_set = set() # Used to store permutations/combinations\n",
    "    \n",
    "    h_real = tuple(sorted(unlocked_sequence[:cutoff]))\n",
    "    h_set.add(h_real)\n",
    "    \n",
    "    groups = shapes.values()\n",
    "    counts = []\n",
    "    for shape, nodes in shapes.items():\n",
    "        nodes_shape = [n for n in h_real if n in nodes]\n",
    "        counts += [len(nodes_shape)]\n",
    "        \n",
    "    selections = [combinations(g, c) for g, c in zip(groups, counts)]    \n",
    "    combs = list(product(*selections))\n",
    "    shuffle(combs)\n",
    "    for comb in combs[:5]:\n",
    "        h_set.add(tuple(sorted(chain.from_iterable(comb))))\n",
    "\n",
    "\n",
    "    h_set = list(h_set)\n",
    "    shuffle(h_set)\n",
    "\n",
    "    for i in range(len(h_set)):\n",
    "        print(h_set[i])\n",
    "\n",
    "        if h_set[i] == h_real:\n",
    "            real = i\n",
    "\n",
    "        # Initial State\n",
    "        states = dict()\n",
    "        states[0] = State(t.states[0].literals, None)\n",
    "\n",
    "        unlocked = [node for node in h_set[i]]\n",
    "        not_unlocked = [node for node in all_nodes if node not in unlocked]\n",
    "        \n",
    "\n",
    "        unlocked_nodes = [Literal(\"locked\", [node], False) for node in unlocked]\n",
    "        unlocked_nodes += [Literal(\"locked\", [node], True) for node in not_unlocked]\n",
    "\n",
    "        states[selected_index] = State(unlocked_nodes, None)\n",
    "\n",
    "        hyp = LTLHypothesis(t.objects, states, [], \"\")\n",
    "\n",
    "        H += [hyp]\n",
    "\n",
    "        \n",
    "        \n",
    "    observed_indices = [selected_index]\n",
    "    for observability in observabilities:\n",
    "\n",
    "        path = base_path + \"%s/\" % str(observability)\n",
    "\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "\n",
    "        path = path + \"P%s/\" % str(pcount).zfill(2)\n",
    "\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "\n",
    "\n",
    "\n",
    "        M.to_file(path + \"domain\")\n",
    "        \n",
    "        plan.to_file(path + \"plan_original\")\n",
    "\n",
    "        \n",
    "        \n",
    "        num_observations = int(selected_index * observability / 100)\n",
    "        new_observed_indices = sample(set(range(selected_index)).difference(set(observed_indices)), k=num_observations-len(observed_indices))\n",
    "        observed_indices += new_observed_indices\n",
    "\n",
    "        print(observed_indices)\n",
    "\n",
    "        obs = Ms.observe_trajectory(t).select_observations(observed_indices)\n",
    "\n",
    "#         print(obs)\n",
    "#         obs.to_file(path + \"obs\")\n",
    "\n",
    "        observations = obs.observations\n",
    "\n",
    "        for i in range(len(H)):\n",
    "            H[i].observations = observations\n",
    "            \n",
    "            state_keys = sorted(H[i].states.keys())\n",
    "            observation_keys = sorted(H[i].observations.keys())\n",
    "            keys = sorted(list(set(state_keys).union(observation_keys)))\n",
    "            \n",
    "            phis = []\n",
    "            for k in keys:\n",
    "                if k in state_keys and k in observation_keys:\n",
    "                    phis += [\"s{} & o{}\".format(k,k)]\n",
    "                elif k in state_keys:\n",
    "                    phis += [\"s{}\".format(k)]\n",
    "                else:\n",
    "                    phis += [\"o{}\".format(k)]\n",
    "            \n",
    "            formula = ordered_occurrence(phis)\n",
    "            H[i].formula = formula\n",
    "            \n",
    "            H[i].to_file(path + \"hyp%s\" % str(i).zfill(2))\n",
    "\n",
    "        with open(path + \"sol\", \"w\") as f:\n",
    "                      f.write(str(real))\n",
    "\n",
    "    pcount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dieaigar/PhD/downward/fast-downward.py --plan-file solution_plan domain.pddl problem.pddl --evaluator \"lmc=merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1)\" --search \"astar(lmc,lazy_evaluator=lmc)\"\n",
      "['node34', 'node44']\n",
      "[19, 24]\n",
      "19\n",
      "('node34', 'node44')\n",
      "('node44', 'node34')\n",
      "[14, 4, 12, 3, 7]\n",
      "[14, 4, 12, 3, 7, 11, 13, 6, 15]\n",
      "[14, 4, 12, 3, 7, 11, 13, 6, 15, 10, 8, 1, 17]\n",
      "/home/dieaigar/PhD/downward/fast-downward.py --plan-file solution_plan domain.pddl problem.pddl --evaluator \"lmc=merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1)\" --search \"astar(lmc,lazy_evaluator=lmc)\"\n",
      "['node34', 'node44']\n",
      "[14, 19]\n",
      "14\n",
      "('node44', 'node34')\n",
      "('node34', 'node44')\n",
      "[11, 13, 2, 9]\n",
      "[11, 13, 2, 9, 3, 8, 7]\n",
      "[11, 13, 2, 9, 3, 8, 7, 1, 5]\n",
      "/home/dieaigar/PhD/downward/fast-downward.py --plan-file solution_plan domain.pddl problem.pddl --evaluator \"lmc=merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1)\" --search \"astar(lmc,lazy_evaluator=lmc)\"\n",
      "['node34', 'node44']\n",
      "[16, 21]\n",
      "16\n",
      "('node44', 'node34')\n",
      "('node34', 'node44')\n",
      "[10, 13, 2, 6]\n",
      "[10, 13, 2, 6, 8, 7, 4, 11]\n",
      "[10, 13, 2, 6, 8, 7, 4, 11, 3, 1, 9]\n",
      "/home/dieaigar/PhD/downward/fast-downward.py --plan-file solution_plan domain.pddl problem.pddl --evaluator \"lmc=merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1)\" --search \"astar(lmc,lazy_evaluator=lmc)\"\n",
      "['node43', 'node44']\n",
      "[13, 20]\n",
      "13\n",
      "('node43', 'node44')\n",
      "('node44', 'node43')\n",
      "[2, 5, 3]\n",
      "[2, 5, 3, 6, 9, 12]\n",
      "[2, 5, 3, 6, 9, 12, 11, 0, 4]\n",
      "/home/dieaigar/PhD/downward/fast-downward.py --plan-file solution_plan domain.pddl problem.pddl --evaluator \"lmc=merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1)\" --search \"astar(lmc,lazy_evaluator=lmc)\"\n",
      "['node34', 'node44']\n",
      "[13, 20]\n",
      "13\n",
      "('node44', 'node34')\n",
      "('node34', 'node44')\n",
      "[3, 4, 6]\n",
      "[3, 4, 6, 0, 5, 7]\n",
      "[3, 4, 6, 0, 5, 7, 11, 1, 8]\n",
      "/home/dieaigar/PhD/downward/fast-downward.py --plan-file solution_plan domain.pddl problem.pddl --evaluator \"lmc=merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1)\" --search \"astar(lmc,lazy_evaluator=lmc)\"\n",
      "['node34', 'node44']\n",
      "[14, 19]\n",
      "14\n",
      "('node44', 'node34')\n",
      "('node34', 'node44')\n",
      "[5, 0, 10, 8]\n",
      "[5, 0, 10, 8, 2, 3, 13]\n",
      "[5, 0, 10, 8, 2, 3, 13, 1, 9]\n",
      "/home/dieaigar/PhD/downward/fast-downward.py --plan-file solution_plan domain.pddl problem.pddl --evaluator \"lmc=merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1)\" --search \"astar(lmc,lazy_evaluator=lmc)\"\n",
      "['node34', 'node44']\n",
      "[19, 24]\n",
      "19\n",
      "('node34', 'node44')\n",
      "('node44', 'node34')\n",
      "[7, 4, 16, 3, 8]\n",
      "[7, 4, 16, 3, 8, 18, 6, 14, 1]\n",
      "[7, 4, 16, 3, 8, 18, 6, 14, 1, 12, 15, 0, 17]\n",
      "/home/dieaigar/PhD/downward/fast-downward.py --plan-file solution_plan domain.pddl problem.pddl --evaluator \"lmc=merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1)\" --search \"astar(lmc,lazy_evaluator=lmc)\"\n",
      "['node34', 'node44']\n",
      "[18, 23]\n",
      "18\n",
      "('node34', 'node44')\n",
      "('node44', 'node34')\n",
      "[0, 16, 15, 9, 14]\n",
      "[0, 16, 15, 9, 14, 7, 11, 17, 5]\n",
      "[0, 16, 15, 9, 14, 7, 11, 17, 5, 1, 12, 8]\n",
      "/home/dieaigar/PhD/downward/fast-downward.py --plan-file solution_plan domain.pddl problem.pddl --evaluator \"lmc=merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1)\" --search \"astar(lmc,lazy_evaluator=lmc)\"\n",
      "['node34', 'node44']\n",
      "[20, 25]\n",
      "20\n",
      "('node34', 'node44')\n",
      "('node44', 'node34')\n",
      "[17, 15, 12, 11, 5, 16]\n",
      "[17, 15, 12, 11, 5, 16, 0, 18, 13, 8]\n",
      "[17, 15, 12, 11, 5, 16, 0, 18, 13, 8, 1, 3, 4, 10]\n",
      "/home/dieaigar/PhD/downward/fast-downward.py --plan-file solution_plan domain.pddl problem.pddl --evaluator \"lmc=merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1)\" --search \"astar(lmc,lazy_evaluator=lmc)\"\n",
      "['node34', 'node44']\n",
      "[19, 24]\n",
      "19\n",
      "('node34', 'node44')\n",
      "('node44', 'node34')\n",
      "[0, 5, 10, 13, 9]\n",
      "[0, 5, 10, 13, 9, 11, 16, 7, 6]\n",
      "[0, 5, 10, 13, 9, 11, 16, 7, 6, 8, 18, 17, 15]\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "\n",
    "shapes = {\"triangle\" : [\"node44\",\"node23\",\"node32\"], \"circle\" : [\"node34\",\"node33\",\"node43\"], \"square\" : [\"node24\",\"node22\",\"node42\"]}\n",
    "all_nodes = [node for sublist in shapes.values() for node in sublist]\n",
    "\n",
    "observabilities = [30, 50, 70]\n",
    "cutoff = 2\n",
    "\n",
    "base_path = \"benchmark/%s/prediction/\" % (domain)\n",
    "\n",
    "if not os.path.exists(base_path):\n",
    "    os.mkdir(base_path)\n",
    "\n",
    "    \n",
    "pcount = 0\n",
    "for pnum in range(10):\n",
    "    \n",
    "    P = parse_problem(\"%s/p%s.pddl\" % (domain, str(pnum+1).zfill(2)), M)\n",
    "    P.to_file(\"problem.pddl\")\n",
    "\n",
    "    print(cmd)\n",
    "    os.system(cmd)\n",
    "\n",
    "    plan = parse_plan(\"solution_plan\")\n",
    "\n",
    "    t = generate_trajectory(M, P, plan)\n",
    "\n",
    "\n",
    "\n",
    "    unlocked_sequence = []\n",
    "    unlocked_states = []\n",
    "\n",
    "    for i in t.states.keys():\n",
    "        open_nodes = [l.args[0]for l in t.states[i].to_close_world().literals if l.predicate == \"open\"]\n",
    "        unlocked_nodes = [node for node in open_nodes if node in all_nodes]\n",
    "\n",
    "        for node in unlocked_nodes:\n",
    "            if node not in unlocked_sequence:\n",
    "                unlocked_sequence += [node]\n",
    "\n",
    "                unlocked_states += [i]\n",
    "\n",
    "\n",
    "    already_unlocked = unlocked_sequence[:-cutoff]\n",
    "    unlocked_sequence = unlocked_sequence[-cutoff:]\n",
    "    unlocked_states = unlocked_states[-cutoff:]\n",
    "    max_index = unlocked_states[0]\n",
    "\n",
    "    print(unlocked_sequence)\n",
    "    print(unlocked_states)\n",
    "    print(max_index)\n",
    "\n",
    "\n",
    "    # Build hypotheses\n",
    "\n",
    "    H = [] # Hypotheses set\n",
    "    h_set = set() # Used to store permutations/combinations\n",
    "\n",
    "    \n",
    "    h_real = tuple(unlocked_sequence)\n",
    "    h_set.add(h_real)\n",
    "\n",
    "    for perm in list(permutations(unlocked_sequence, cutoff))[:5]:\n",
    "        h_set.add(perm)\n",
    "\n",
    "\n",
    "    h_set = list(h_set)\n",
    "    shuffle(h_set)\n",
    "\n",
    "    for i in range(len(h_set)):\n",
    "        print(h_set[i])\n",
    "\n",
    "        if h_set[i] == h_real:\n",
    "            real = i\n",
    "\n",
    "        # Initial State\n",
    "        states = dict()\n",
    "        states[0] = State(t.states[0].literals, None)\n",
    "\n",
    "        # Start h with last 3 not unlocked\n",
    "        unlocked_nodes = [Literal(\"locked\", [node], False) for node in already_unlocked]\n",
    "        unlocked_nodes += [Literal(\"locked\", [node], True) for node in h_set[i]]\n",
    "\n",
    "        states[unlocked_states[0]-1] = State(unlocked_nodes,None)\n",
    "\n",
    "\n",
    "        unlocked = []\n",
    "        not_unlocked = [node for node in h_set[i]]\n",
    "\n",
    "        for k in range(cutoff):\n",
    "            unlocked += [not_unlocked.pop(0)]\n",
    "\n",
    "            unlocked_nodes = [Literal(\"locked\", [node], False) for node in already_unlocked]\n",
    "            unlocked_nodes += [Literal(\"locked\", [node], False) for node in unlocked]\n",
    "            unlocked_nodes += [Literal(\"locked\", [node], True) for node in not_unlocked]\n",
    "\n",
    "            states[unlocked_states[k]] = State(unlocked_nodes, None)\n",
    "            \n",
    "        # Add goal as last state to the hypothesis\n",
    "#         shipped_nodes = [Literal(\"shipped\", [node], True) for node in all_nodes]\n",
    "#         states[len(t.states)-1] = State(shipped_nodes, None)\n",
    "        \n",
    "\n",
    "        hyp = Hypothesis(t.objects, states)\n",
    "\n",
    "        H += [hyp]\n",
    "\n",
    "    observed_indices = []\n",
    "    for observability in observabilities:\n",
    "\n",
    "        path = base_path + \"%s/\" % str(observability)\n",
    "\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "\n",
    "        path = path + \"P%s/\" % str(pcount).zfill(2)\n",
    "\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "\n",
    "\n",
    "\n",
    "        M.to_file(path + \"domain\")\n",
    "        \n",
    "        plan.to_file(path + \"plan_original\")\n",
    "\n",
    "\n",
    "        num_observations = int(max_index * observability / 100)\n",
    "        new_observed_indices = sample(set(range(max_index)).difference(set(observed_indices)), k=num_observations-len(observed_indices))\n",
    "        observed_indices += new_observed_indices\n",
    "\n",
    "        print(observed_indices)\n",
    "\n",
    "        obs = Ms.observe_trajectory(t).select_observations(observed_indices)\n",
    "\n",
    "#         print(obs)\n",
    "        obs.to_file(path + \"obs\")\n",
    "\n",
    "        for i in range(len(H)):\n",
    "            H[i].to_file(path + \"hyp%s\" % str(i).zfill(2))\n",
    "\n",
    "        with open(path + \"sol\", \"w\") as f:\n",
    "                      f.write(str(real))\n",
    "\n",
    "    pcount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dieaigar/PhD/downward/fast-downward.py --plan-file solution_plan domain.pddl problem.pddl --evaluator \"lmc=merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1)\" --search \"astar(lmc,lazy_evaluator=lmc)\"\n",
      "['node32', 'node33']\n",
      "[9, 17]\n",
      "36\n",
      "('node33', 'node32')\n",
      "('node32', 'node33')\n",
      "[9, 10, 17, 6, 18, 21, 27, 4, 20, 2]\n",
      "[9, 10, 17, 6, 18, 21, 27, 4, 20, 2, 5, 28, 15, 0, 19, 16, 33, 22]\n",
      "[9, 10, 17, 6, 18, 21, 27, 4, 20, 2, 5, 28, 15, 0, 19, 16, 33, 22, 32, 31, 29, 30, 23, 26, 12]\n",
      "/home/dieaigar/PhD/downward/fast-downward.py --plan-file solution_plan domain.pddl problem.pddl --evaluator \"lmc=merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1)\" --search \"astar(lmc,lazy_evaluator=lmc)\"\n",
      "['node23', 'node33']\n",
      "[4, 12]\n",
      "31\n",
      "('node23', 'node33')\n",
      "('node33', 'node23')\n",
      "[27, 15, 21, 18, 28, 25, 2, 23, 7]\n",
      "[27, 15, 21, 18, 28, 25, 2, 23, 7, 8, 22, 29, 10, 17, 13]\n",
      "[27, 15, 21, 18, 28, 25, 2, 23, 7, 8, 22, 29, 10, 17, 13, 26, 12, 1, 4, 19, 16]\n",
      "/home/dieaigar/PhD/downward/fast-downward.py --plan-file solution_plan domain.pddl problem.pddl --evaluator \"lmc=merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1)\" --search \"astar(lmc,lazy_evaluator=lmc)\"\n",
      "['node23', 'node33']\n",
      "[6, 14]\n",
      "33\n",
      "('node23', 'node33')\n",
      "('node33', 'node23')\n",
      "[5, 0, 4, 27, 30, 20, 19, 16, 2]\n",
      "[5, 0, 4, 27, 30, 20, 19, 16, 2, 8, 15, 14, 23, 17, 18, 12]\n",
      "[5, 0, 4, 27, 30, 20, 19, 16, 2, 8, 15, 14, 23, 17, 18, 12, 25, 13, 7, 21, 32, 31, 28]\n",
      "/home/dieaigar/PhD/downward/fast-downward.py --plan-file solution_plan domain.pddl problem.pddl --evaluator \"lmc=merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1)\" --search \"astar(lmc,lazy_evaluator=lmc)\"\n",
      "['node42', 'node43']\n",
      "[11, 13]\n",
      "32\n",
      "('node43', 'node42')\n",
      "('node42', 'node43')\n",
      "[16, 9, 12, 4, 18, 23, 29, 19, 6]\n",
      "[16, 9, 12, 4, 18, 23, 29, 19, 6, 10, 24, 14, 25, 0, 17, 31]\n",
      "[16, 9, 12, 4, 18, 23, 29, 19, 6, 10, 24, 14, 25, 0, 17, 31, 26, 5, 28, 3, 15, 22]\n",
      "/home/dieaigar/PhD/downward/fast-downward.py --plan-file solution_plan domain.pddl problem.pddl --evaluator \"lmc=merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1)\" --search \"astar(lmc,lazy_evaluator=lmc)\"\n",
      "['node23', 'node33']\n",
      "[8, 11]\n",
      "32\n",
      "('node23', 'node33')\n",
      "('node33', 'node23')\n",
      "[19, 20, 5, 11, 3, 6, 9, 30, 8]\n",
      "[19, 20, 5, 11, 3, 6, 9, 30, 8, 0, 15, 28, 21, 12, 17, 7]\n",
      "[19, 20, 5, 11, 3, 6, 9, 30, 8, 0, 15, 28, 21, 12, 17, 7, 4, 10, 26, 16, 25, 18]\n",
      "/home/dieaigar/PhD/downward/fast-downward.py --plan-file solution_plan domain.pddl problem.pddl --evaluator \"lmc=merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1)\" --search \"astar(lmc,lazy_evaluator=lmc)\"\n",
      "['node32', 'node33']\n",
      "[4, 12]\n",
      "31\n",
      "('node33', 'node32')\n",
      "('node32', 'node33')\n",
      "[29, 30, 9, 10, 3, 2, 16, 13, 17]\n",
      "[29, 30, 9, 10, 3, 2, 16, 13, 17, 8, 7, 22, 12, 20, 23]\n",
      "[29, 30, 9, 10, 3, 2, 16, 13, 17, 8, 7, 22, 12, 20, 23, 11, 18, 19, 4, 27, 0]\n",
      "/home/dieaigar/PhD/downward/fast-downward.py --plan-file solution_plan domain.pddl problem.pddl --evaluator \"lmc=merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1)\" --search \"astar(lmc,lazy_evaluator=lmc)\"\n",
      "['node32', 'node33']\n",
      "[5, 17]\n",
      "36\n",
      "('node32', 'node33')\n",
      "('node33', 'node32')\n",
      "[29, 2, 0, 23, 11, 7, 6, 14, 24, 19]\n",
      "[29, 2, 0, 23, 11, 7, 6, 14, 24, 19, 10, 32, 17, 12, 35, 16, 26, 30]\n",
      "[29, 2, 0, 23, 11, 7, 6, 14, 24, 19, 10, 32, 17, 12, 35, 16, 26, 30, 33, 21, 31, 3, 1, 9, 15]\n",
      "/home/dieaigar/PhD/downward/fast-downward.py --plan-file solution_plan domain.pddl problem.pddl --evaluator \"lmc=merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1)\" --search \"astar(lmc,lazy_evaluator=lmc)\"\n",
      "['node23', 'node33']\n",
      "[8, 16]\n",
      "35\n",
      "('node23', 'node33')\n",
      "('node33', 'node23')\n",
      "[25, 12, 6, 26, 33, 19, 28, 13, 24, 0]\n",
      "[25, 12, 6, 26, 33, 19, 28, 13, 24, 0, 31, 14, 27, 23, 4, 5, 3]\n",
      "[25, 12, 6, 26, 33, 19, 28, 13, 24, 0, 31, 14, 27, 23, 4, 5, 3, 34, 16, 29, 32, 20, 9, 18]\n",
      "/home/dieaigar/PhD/downward/fast-downward.py --plan-file solution_plan domain.pddl problem.pddl --evaluator \"lmc=merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1)\" --search \"astar(lmc,lazy_evaluator=lmc)\"\n",
      "['node32', 'node33']\n",
      "[10, 18]\n",
      "37\n",
      "('node33', 'node32')\n",
      "('node32', 'node33')\n",
      "[4, 8, 28, 10, 32, 36, 16, 30, 1, 3, 25]\n",
      "[4, 8, 28, 10, 32, 36, 16, 30, 1, 3, 25, 7, 26, 31, 15, 21, 18, 14]\n",
      "[4, 8, 28, 10, 32, 36, 16, 30, 1, 3, 25, 7, 26, 31, 15, 21, 18, 14, 0, 35, 13, 27, 22, 5, 24]\n",
      "/home/dieaigar/PhD/downward/fast-downward.py --plan-file solution_plan domain.pddl problem.pddl --evaluator \"lmc=merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1)\" --search \"astar(lmc,lazy_evaluator=lmc)\"\n",
      "['node23', 'node33']\n",
      "[7, 17]\n",
      "36\n",
      "('node23', 'node33')\n",
      "('node33', 'node23')\n",
      "[2, 27, 1, 3, 20, 5, 9, 15, 25, 12]\n",
      "[2, 27, 1, 3, 20, 5, 9, 15, 25, 12, 30, 6, 7, 4, 34, 29, 19, 14]\n",
      "[2, 27, 1, 3, 20, 5, 9, 15, 25, 12, 30, 6, 7, 4, 34, 29, 19, 14, 26, 10, 32, 13, 23, 31, 0]\n"
     ]
    }
   ],
   "source": [
    "# Hindsight\n",
    "\n",
    "shapes = {\"triangle\" : [\"node44\",\"node23\",\"node32\"], \"circle\" : [\"node34\",\"node33\",\"node43\"], \"square\" : [\"node24\",\"node22\",\"node42\"]}\n",
    "all_nodes = [node for sublist in shapes.values() for node in sublist]\n",
    "\n",
    "observabilities = [30, 50, 70]\n",
    "cutoff = 2\n",
    "\n",
    "\n",
    "base_path = \"benchmark/%s/hindsight/\" % (domain)\n",
    "\n",
    "if not os.path.exists(base_path):\n",
    "    os.mkdir(base_path)\n",
    "\n",
    "    \n",
    "pcount = 0\n",
    "for pnum in range(10):\n",
    "    \n",
    "    P = parse_problem(\"%s/p%s.pddl\" % (domain, str(pnum+1).zfill(2)), M)\n",
    "    P.to_file(\"problem.pddl\")\n",
    "\n",
    "    print(cmd)\n",
    "    os.system(cmd)\n",
    "\n",
    "    plan = parse_plan(\"solution_plan\")\n",
    "\n",
    "    t = generate_trajectory(M, P, plan)\n",
    "\n",
    "\n",
    "\n",
    "    unlocked_sequence = []\n",
    "    unlocked_states = []\n",
    "\n",
    "    for i in t.states.keys():\n",
    "        open_nodes = [l.args[0]for l in t.states[i].to_close_world().literals if l.predicate == \"open\"]\n",
    "        unlocked_nodes = [node for node in open_nodes if node in all_nodes]\n",
    "\n",
    "        for node in unlocked_nodes:\n",
    "            if node not in unlocked_sequence:\n",
    "                unlocked_sequence += [node]\n",
    "\n",
    "                unlocked_states += [i]\n",
    "\n",
    "    unlocked_sequence = unlocked_sequence[:cutoff]\n",
    "    unlocked_states = unlocked_states[:cutoff]\n",
    "    max_index = len(t.states.keys())\n",
    "\n",
    "    print(unlocked_sequence)\n",
    "    print(unlocked_states)\n",
    "    print(max_index)\n",
    "\n",
    "\n",
    "    # Build hypotheses\n",
    "\n",
    "    H = [] # Hypotheses set\n",
    "    h_set = set() # Used to store permutations/combinations\n",
    "    \n",
    "    h_real = tuple(unlocked_sequence)\n",
    "    h_set.add(h_real)\n",
    " \n",
    "    for perm in list(permutations(unlocked_sequence, cutoff))[:5]:\n",
    "        h_set.add(perm)\n",
    " \n",
    "\n",
    "    h_set = list(h_set)\n",
    "    shuffle(h_set)\n",
    "\n",
    "    for i in range(len(h_set)):\n",
    "        print(h_set[i])\n",
    "\n",
    "        if h_set[i] == h_real:\n",
    "            real = i\n",
    "\n",
    "        # Initial State\n",
    "        states = dict()\n",
    "        states[0] = State(t.states[0].literals, None)\n",
    "\n",
    "        unlocked = []\n",
    "        not_unlocked = [node for node in h_set[i]]\n",
    "\n",
    "        for k in range(cutoff):\n",
    "            unlocked += [not_unlocked.pop(0)]\n",
    "\n",
    "            unlocked_nodes = [Literal(\"locked\", [node], False) for node in unlocked]\n",
    "            unlocked_nodes += [Literal(\"locked\", [node], True) for node in not_unlocked]\n",
    "\n",
    "            states[unlocked_states[k]] = State(unlocked_nodes, None)\n",
    "\n",
    "        hyp = Hypothesis(t.objects, states)\n",
    "\n",
    "        H += [hyp]\n",
    "\n",
    "    observed_indices = []\n",
    "    for observability in observabilities:\n",
    "\n",
    "        path = base_path + \"%s/\" % str(observability)\n",
    "\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "\n",
    "        path = path + \"P%s/\" % str(pcount).zfill(2)\n",
    "\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "\n",
    "\n",
    "\n",
    "        M.to_file(path + \"domain\")\n",
    "        \n",
    "        plan.to_file(path + \"plan_original\")\n",
    "\n",
    "\n",
    "        num_observations = int(max_index * observability / 100)\n",
    "        new_observed_indices = sample(set(range(max_index)).difference(set(observed_indices)), k=num_observations-len(observed_indices))\n",
    "        observed_indices += new_observed_indices\n",
    "\n",
    "        print(observed_indices)\n",
    "\n",
    "        obs = Ms.observe_trajectory(t).select_observations(observed_indices)\n",
    "\n",
    "#         print(obs)\n",
    "        obs.to_file(path + \"obs\")\n",
    "\n",
    "        for i in range(len(H)):\n",
    "            H[i].to_file(path + \"hyp%s\" % str(i).zfill(2))\n",
    "\n",
    "        with open(path + \"sol\", \"w\") as f:\n",
    "                      f.write(str(real))\n",
    "\n",
    "    pcount += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inference",
   "language": "python",
   "name": "inference"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
