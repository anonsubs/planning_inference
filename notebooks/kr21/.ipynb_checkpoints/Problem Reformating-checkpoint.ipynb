{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from planning_inference.parsers import parse_model, parse_problem, parse_plan, parse_trajectory, parse_hypothesis, parse_observation_sequence\n",
    "from planning_inference.generator import generate_trajectory\n",
    "from planning_inference.functions import generate_all_literals, get_matching_literals\n",
    "\n",
    "from planning_inference.pddl import Conjunction, Literal, Type, TypedObject, Effect, Truth, NumericConstant, PrimitiveNumericExpression, Increase\n",
    "from planning_inference.pddl import SensorModel\n",
    "\n",
    "from planning_inference.observations import Trajectory, Hypothesis, State, LTLHypothesis\n",
    "\n",
    "from planning_inference import DecodingTask\n",
    "\n",
    "from sensor_models import load_sensor_model\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import copy\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordered_occurrence(phis):\n",
    "    if len(phis) == 1:\n",
    "        return \"{}\".format(phis[0])\n",
    "    else:\n",
    "        return \"{} & X(F({}))\".format(phis[0], ordered_occurrence(phis[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat(domain, task):\n",
    "    \n",
    "    base_path = \"benchmark/%s/%s/\" % (domain,task)\n",
    "\n",
    "    if not os.path.exists(base_path):\n",
    "        os.mkdir(base_path)\n",
    "\n",
    "    observabilities = [30, 50, 70]       \n",
    "    for observability in observabilities:\n",
    "        original_path = \"../aaai21/benchmark/%s/%s/%s/\" % (domain, task, str(observability))\n",
    "        base_path = \"benchmark/%s/%s/%s/\" % (domain, task, str(observability))\n",
    "        \n",
    "        if not os.path.exists(base_path):\n",
    "            os.mkdir(base_path)\n",
    "       \n",
    "\n",
    "        for i in range(10):\n",
    "            \n",
    "            original_problem = original_path + \"P%s/\" % (str(i).zfill(2))\n",
    "            problem = base_path + \"P%s/\" % (str(i).zfill(2))\n",
    "            if not os.path.exists(problem):\n",
    "                os.mkdir(problem)\n",
    "            \n",
    "            shutil.copyfile(original_problem + \"domain\", problem + \"domain\")\n",
    "            shutil.copyfile(original_problem + \"plan_original\", problem + \"plan_original\")\n",
    "            shutil.copyfile(original_problem + \"sol\", problem + \"sol\")\n",
    "\n",
    "            \n",
    "            observation_seq = parse_observation_sequence(original_problem + \"/obs\")\n",
    "            \n",
    "            # Hypotheses\n",
    "            h_files = sorted(glob.glob(original_problem + \"/hyp*\"))\n",
    "            \n",
    "            for j in range(len(h_files)):\n",
    "                h = parse_hypothesis(h_files[j])\n",
    "                \n",
    "                state_keys = sorted(h.states.keys())\n",
    "                observation_keys = sorted(observation_seq.observations.keys())\n",
    "                keys = sorted(list(set(state_keys).union(observation_keys)))\n",
    "\n",
    "                phis = []\n",
    "                for k in keys:\n",
    "                    if k in state_keys and k in observation_keys:\n",
    "                        phis += [\"s{} & o{}\".format(k,k)]\n",
    "                    elif k in state_keys:\n",
    "                        phis += [\"s{}\".format(k)]\n",
    "                    else:\n",
    "                        phis += [\"o{}\".format(k)]\n",
    "\n",
    "                formula = ordered_occurrence(phis)\n",
    "                \n",
    "                LTLh = LTLHypothesis(h.objects, h.states, observation_seq.observations, formula)\n",
    "                \n",
    "                LTLh.to_file(problem + \"hyp%s\" % str(j).zfill(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = \"floortile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MONITORING\n",
    "\n",
    "task = \"monitoring\"\n",
    "reformat(domain, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTION\n",
    "\n",
    "task = \"prediction\"\n",
    "reformat(domain, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HINDSIGHT\n",
    "\n",
    "task = \"hindsight\"\n",
    "reformat(domain, task)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inference",
   "language": "python",
   "name": "inference"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
